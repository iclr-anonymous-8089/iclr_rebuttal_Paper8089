# ICLR_Rebuttal_Paper8089

<p align="center">
  <img src="https://raw.githubusercontent.com/iclr-anonymous-8089/iclr_rebuttal_Paper8089/main/figures/ours_GdvgFV5R1Z5.png" alt="ours_GdvgFV5R1Z5" width="70%">
  <br>
  <em>Figure 1: Camera trajectory and reconstructed point cloud of our method in scene GdvgF of MP3D dataset. The ground truth mesh is displayed with colors, while our reconstructed scene is rendered in white. Our method achieves Comp. of 87.80% in this scene with multiple objects, outperforming state-of-the-art method ANM [1] by absolute 6.81%. Our method efficiently explores different rooms in this scene while successfully avoiding obstacles.</em>
</p>


<p align="center">
  <img src="https://raw.githubusercontent.com/iclr-anonymous-8089/iclr_rebuttal_Paper8089/main/figures/ours_HxpKQ.png" alt="ours_HxpKQ" width="100%">
  <br>
  <em>Figure 2: Camera trajectory and reconstructed point cloud of our method in the challenging scene HxpKQ of MP3D dataset. The ground truth mesh is displayed with colors, while our reconstructed scene is rendered in white. Our method achieves Comp. of 66.28% in this scene with multiple objects, outperforming state-of-the-art method ANM [1] by absolute 17.94%. </em>

</p>

<table align="center" width="100%">
 <tr>
   <!-- Image cells -->
   <td width="50%"><img src="https://raw.githubusercontent.com/iclr-anonymous-8089/iclr_rebuttal_Paper8089/main/figures/ANM [1]_HxpKQ* .png" alt="ANM [1]_HxpKQ*" style="width:100%; height:auto;"></td>
   <td width="50%"><img src="https://raw.githubusercontent.com/iclr-anonymous-8089/iclr_rebuttal_Paper8089/main/figures/gt_HxpKQ.png" alt="gt_HxpKQ" style="width:100%; height:auto;"></td>
 </tr>
 <tr>
   <!-- Caption cells -->
   <td align="center" width="50%"><em>Figure 3: For comparison, we include the camera trajectory and reconstructed scene (shown in blue) by ANM method [1] in the challenging scene HxpKQ of MP3D dataset. The starting camera pose is the same as in Figure 2. However, the agent gets stuck near the bed, failing to conduct effective exploration. The figure is sourced from ANM supplementary material.</em></td>
   <td align="center" width="50%"><em>Figure 4: Ground truth mesh of scene HxpKQ.</em></td>
 </tr>
</table>


[1] Yan, Zike, Haoxiang Yang, and Hongbin Zha. "Active neural mapping." Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.
